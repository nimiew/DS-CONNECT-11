{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS CONNECT 11\n",
    "## How to build your own image classifier with limited images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Code is highly abstracted. Bulk of the logic is in utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cZZS9CvGa_Qf",
    "outputId": "9a9d103e-a8f5-4229-d115-e652f0eb75f5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Select GPU #0\n",
    "import keras\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images into test and train folders with the preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CTq6WG9CPLq"
   },
   "outputs": [],
   "source": [
    "utils.preprocess(test_percentage=0.50, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at some images in our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic CNN and look at its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "OrVuDVHwWnAp",
    "outputId": "725626b2-faf5-47f0-dd1e-1449ac4053d9"
   },
   "outputs": [],
   "source": [
    "model = utils.create_basic_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qB0b2oCUWng5"
   },
   "outputs": [],
   "source": [
    "utils.compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bTD3iKJ-Wnpd",
    "outputId": "f64cc752-7014-4aff-8b2e-4b4b03e07adb"
   },
   "outputs": [],
   "source": [
    "#utils.train(model, 'train', 'test', 1000, 'model.h5')\n",
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.evaluate(model, 'train', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal CNN takes a long time to train, lets try transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CNN Base of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lwJ6aVYBpRM5",
    "outputId": "101426ef-c859-443c-f43a-ea71f11201d7"
   },
   "outputs": [],
   "source": [
    "#Use transfer learning for feature extraction\n",
    "feature_extractor = utils.create_conv_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and labels from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "uahZ_UztpRRe",
    "outputId": "87300697-577e-40e1-bbd8-a941002367d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = utils.extract_features(feature_extractor, 'train', utils.num_samples('train'))\n",
    "test_features, test_labels = utils.extract_features(feature_extractor, 'test', utils.num_samples('test'))\n",
    "train_features, test_features = utils.reshape_features(train_features), utils.reshape_features(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multi-layer-perceptron network for training the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZJAT_PepRSf"
   },
   "outputs": [],
   "source": [
    "mlp = utils.create_MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compile(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#utils.train_MLP(mlp, train_features, train_labels, test_features, test_labels, 5000, 'mlp.h5') # 141 epochs\n",
    "mlp = keras.models.load_model(\"mlp.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.evaluate_MLP(mlp, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Nb3YkZIepRXV",
    "outputId": "840971a0-8697-408e-8464-bfd5a20424ee"
   },
   "source": [
    "We get much better results even with less training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if you have less training data? \n",
    "## We will simulate this by only using 10% of data as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.preprocess(test_percentage=0.90, augment=False) # Use only 10% of data as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = utils.extract_features(feature_extractor, 'train', utils.num_samples('train'))\n",
    "test_features, test_labels = utils.extract_features(feature_extractor, 'test', utils.num_samples('test'))\n",
    "train_features, test_features = utils.reshape_features(train_features), utils.reshape_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp2 = utils.create_MLP()\n",
    "utils.compile(mlp2)\n",
    "#utils.train_MLP(mlp2, train_features, train_labels, test_features, test_labels, 5000, 'mlp2.h5') # 453 epochs\n",
    "mlp2 = keras.models.load_model(\"mlp2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.evaluate_MLP(mlp2, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we get much poorer results when we use significantly less data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can improve this further with data augmentation, which is particularly useful when we have a small dataset\n",
    "\n",
    "How this works is that we augment the images randomly before extracting features\n",
    "\n",
    "We will compare the results with and without image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.preprocess(test_percentage=0.90, augment=True) # Also use 10% of data as training data, but augment to x10 the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "-LIWCvqAB0yC",
    "outputId": "550c3333-9581-4f78-efa1-ea0c7b833ab4"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = utils.extract_features(feature_extractor, 'aug_train', utils.num_samples('aug_train'))\n",
    "test_features, test_labels = utils.extract_features(feature_extractor, 'test', utils.num_samples('test'))\n",
    "train_features, test_features = utils.reshape_features(train_features), utils.reshape_features(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.show_augment_image() # go to aug_train folder to see images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results. We create, compile and train the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt25tT4fiAf2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp3 = utils.create_MLP()\n",
    "utils.compile(mlp3)\n",
    "#utils.train_MLP(mlp3, train_features, train_labels, test_features, test_labels, 5000, 'mlp3.h5') # 92 epochs\n",
    "mlp3 = keras.models.load_model(\"mlp3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.evaluate_MLP(mlp3, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we get much better accuracy because we 'expanded' our dataset through image augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets have some fun predicting images with our classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use mlp which is our classifier trained on 50% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Places images in predict\\images folder\n",
    "# Output will also be found in output folder\n",
    "# Note that when this is run, it overwrites all data in output folder\n",
    "utils.predict_and_show(mlp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bike_vs_Trolley.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
